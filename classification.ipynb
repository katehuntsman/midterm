{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mushroom Classification Project\n",
    "### Author: Kate Huntsman\n",
    "### Date: March 21st, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This project aims to classify mushrooms as edible or poisonous using the UCI Mushroom Dataset.\n",
    "We will explore the dataset, preprocess the data, and train machine learning models to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data\n",
    "### 1.1 Load the dataset and display the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv('mushrooms.csv')\n",
    "\n",
    "# Display the first 10 rows\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Check for missing values and display summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Display summary statistics\n",
    "print(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 1: What do you notice about the dataset? Are there any data issues?\n",
    "The dataset has categorical features and no missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2. Data Exploration and Preparation\n",
    "### 2.1 Explore Data Patterns and Distributions\n",
    "Create histograms, boxplots, and count plots for categorical variables (as applicable).\n",
    "Identify patterns, outliers, and anomalies in feature distributions.\n",
    "Check for class imbalance in the target variable (as applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(x='class', data=data, palette='coolwarm')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Explore categorical feature distributions\n",
    "for column in data.columns[1:]:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=column, data=data, palette='viridis')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "class_counts = data['class'].value_counts()\n",
    "print(\"Class Distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Handle missing values and clean data\n",
    "Impute or drop missing values (as applicable).\n",
    "Remove or transform outliers (as applicable).\n",
    "Convert categorical data to numerical format using encoding (as applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for column in data.columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Verify encoding\n",
    "print(\"Encoded Data Sample:\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Feature selection and engineering\n",
    "Create new features (as applicable).\n",
    "Transform or combine existing features to improve model performance (as applicable).\n",
    "Scale or normalize data (as applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = data.drop(columns=['class'])\n",
    "y = data['class']\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 2: What patterns or anomalies do you see? Do any features stand out? What preprocessing steps were necessary to clean and improve the data? Did you create or modify any features to improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "### 3.1 Choose features and target\n",
    "Select two or more input features (numerical for regression, numerical and/or categorical for classification)\n",
    "Select a target variable (as applicable)\n",
    "Regression: Continuous target variable (e.g., price, temperature).\n",
    "Classification: Categorical target variable (e.g., gender, species).\n",
    "Clustering: No target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns.tolist()\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define X and y\n",
    "Assign input features to X\n",
    "Assign target variable to y (as applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 3: Why did you choose these features? How might they impact predictions or accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Train a Model (Classification: Choose 1: Decision Tree, Random Forest, Logistic Regression)\n",
    "### 4.1 Split the data into training and test sets using train_test_split (or StratifiedShuffleSplit if class imbalance is an issue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Decision Tree model\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "print(\"Decision Tree Classifier Performance:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "# Store performance metrics\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "dt_recall = recall_score(y_test, y_pred_dt)\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train model using Scikit-Learn model.fit() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evalulate performance, for example:\n",
    "Regression: R^2, MAE, RMSE (RMSE has been recently updated)\n",
    "Classification: Accuracy, Precision, Recall, F1-score, Confusion Matrix\n",
    "Clustering: Inertia, Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 4: How well did the model perform? Any surprises in the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5. Improve the Model or Try Alternates (Implement a Second Option)\n",
    "### 5.1 Train an alternative classifier (e.g., Decision Tree, Random Forest, Logistic Regression) OR adjust hyperparameters on the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the alternative model\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "print(\"Random Forest Classifier Performance:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Store performance metrics\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Compare performance of all models across the same performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(f\"Decision Tree - Accuracy: {dt_accuracy:.4f}, Precision: {dt_precision:.4f}, Recall: {dt_recall:.4f}, F1-score: {dt_f1:.4f}\")\n",
    "print(f\"Random Forest - Accuracy: {rf_accuracy:.4f}, Precision: {rf_precision:.4f}, Recall: {rf_recall:.4f}, F1-score: {rf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 5: Which model performed better? Why might one classifier be more effective in this specific case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6. Final Thoughts & Insights\n",
    "### 6.1 Summarize findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Discuss challenges faced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 If you had more time, what would you try next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection 6: What did you learn from this project?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
